{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global imports\n",
    "import numpy as np\n",
    "# pyspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as W\n",
    "# machine learning models\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.classification import NaiveBayes, LinearSVC, LogisticRegression\n",
    "# evaluator\n",
    "from pyspark.ml.evaluation import Evaluator\n",
    "# cross validation\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "%store -r dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|           count_vec|label|            weights|\n",
      "+--------------------+-----+-------------------+\n",
      "|(495,[1,2,43,279]...|    0|0.08970309538850285|\n",
      "|(495,[0,2,7,8,10,...|    0|0.08970309538850285|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import train data\n",
    "train_start = spark.createDataFrame(dfs[0])\n",
    "train_start.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           count_vec|label|\n",
      "+--------------------+-----+\n",
      "|         (495,[],[])|    0|\n",
      "|(495,[1,5,6,7,10,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import test data\n",
    "test = spark.createDataFrame(dfs[1])\n",
    "test.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vocabulary\n",
    "vocab = dfs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Folds in Train\n",
    "\n",
    "`fold` column specifies which fold each row belongs to for stratified cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+----+\n",
      "|           count_vec|label|           weights|fold|\n",
      "+--------------------+-----+------------------+----+\n",
      "|(495,[6,56,59,78,...|    1|0.9102969046114971|   1|\n",
      "|(495,[1,3,4,5,6,8...|    1|0.9102969046114971|   2|\n",
      "+--------------------+-----+------------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# shuffle the dataset\n",
    "shuffled = train_start.orderBy(W.rand(340))\n",
    "# create folds for positive and negative classes\n",
    "positive = train_start.filter(shuffled['label']==1)\\\n",
    "                      .withColumn('id', W.row_number().over(Window.orderBy(W.lit('A'))))\\\n",
    "                      .withColumn('fold', W.col('id')%5).drop('id')\n",
    "negative = train_start.filter(shuffled['label']==0)\\\n",
    "                      .withColumn('id', W.row_number().over(Window.orderBy(W.lit('A'))))\\\n",
    "                      .withColumn('fold', W.col('id')%5).drop('id')\n",
    "# combine data frames\n",
    "train = positive.unionAll(negative)\n",
    "# output data frame\n",
    "train.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for fMeasure\n",
    "class fMeasure(Evaluator):\n",
    "    def __init__(self, predictionCol=\"prediction\", labelCol=\"label\"):\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "    def _evaluate(self, dataset):\n",
    "        tp = dataset.where(dataset[self.labelCol]==1).filter(\n",
    "            dataset[self.labelCol]==dataset[self.predictionCol]).count()\n",
    "        fp = dataset.where(dataset[self.labelCol]==0).filter(\n",
    "            dataset[self.labelCol]!=dataset[self.predictionCol]).count()\n",
    "        fn = dataset.where(dataset[self.labelCol]==1).filter(\n",
    "            dataset[self.labelCol]!=dataset[self.predictionCol]).count()\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        if (tp+fp) != 0:\n",
    "            precision = tp/(tp+fp)\n",
    "        if (tp+fn) != 0:\n",
    "            recall = tp/(tp+fn)\n",
    "        if (precision+recall) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return (2*precision*recall)/(precision+recall)\n",
    "    def isLargerBetter(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create f1 score evaluator\n",
    "f1_score = fMeasure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for accuracy\n",
    "class accuracy(Evaluator):\n",
    "    def __init__(self, predictionCol=\"prediction\", labelCol=\"label\"):\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "    def _evaluate(self, dataset):\n",
    "        return dataset.filter(dataset[self.labelCol]==dataset[self.predictionCol]).count()/dataset.count()\n",
    "    def isLargerBetter(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create accuracy evaluator\n",
    "accuracy = accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Stratified Cross Validator\n",
    "\n",
    "Very basic stratified cross validator that can be used with 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is designed for 5 fold cross validation\n",
    "# I tried other iterations that are more flexible but have significantly longer run times\n",
    "class stratifiedCV(CrossValidator):\n",
    "    def __init__(self,estimator=None,estimatorParamMaps=None,evauator=None):\n",
    "        super(stratifiedCV, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self._set(**kwargs)\n",
    "    def _fit(self, dataset):\n",
    "        est = self.getOrDefault(self.estimator)\n",
    "        epm = self.getOrDefault(self.estimatorParamMaps)\n",
    "        numModels = len(epm)\n",
    "        eva = self.getOrDefault(self.evaluator)\n",
    "        metrics = [0.0]*numModels\n",
    "        for i in range(5):\n",
    "            train = dataset.filter(W.col('fold')!=i)\n",
    "            validation = dataset.filter(W.col('fold')==i)\n",
    "            models = est.fit(train,epm)\n",
    "            for j in range(numModels):\n",
    "                model = models[j]\n",
    "                metric = eva.evaluate(model.transform(validation,epm[j]))\n",
    "                metrics[j] += metric/5\n",
    "        if eva.isLargerBetter():\n",
    "            bestIndex = np.argmax(metrics)\n",
    "        else:\n",
    "            bestIndex = np.argmin(metrics)\n",
    "        bestModel = est.fit(dataset,epm[bestIndex])\n",
    "        return self._copyValues(CrossValidatorModel(bestModel,metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation***\n",
    "\n",
    "Tune `stepSize` and `maxIter` parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # create gbt model\n",
    "gbt_cv = GBTClassifier(featuresCol='count_vec', labelCol='label').setSeed(987) # parameter grid\n",
    "gbt_pars = ParamGridBuilder().addGrid(gbt_cv.stepSize,[0.1,0.5,0.9])\\\n",
    "                             .addGrid(gbt_cv.maxIter,[50,100,200])\\\n",
    "                             .build()\n",
    "# create cross validator\n",
    "cv_gbt = stratifiedCV().setEstimator(gbt_cv)\\\n",
    "                       .setEvaluator(f1_score)\\\n",
    "                       .setEstimatorParamMaps(gbt_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best step size:  0.9\n",
      "Best number of trees:  200\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_gbt_model = cv_gbt.fit(train)\n",
    "# get best model\n",
    "best_gbt = cv_gbt_model.bestModel\n",
    "# output best parameters\n",
    "print('Best step size: ',best_gbt._java_obj.getStepSize())\n",
    "print('Best number of trees: ',best_gbt._java_obj.getMaxIter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Final Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "gbt = GBTClassifier(featuresCol='count_vec',labelCol='label',\n",
    "                   stepSize=0.9,maxIter=200).setSeed(987)\n",
    "# train the model\n",
    "gbt_model = gbt.fit(train)\n",
    "# obtain predictions\n",
    "gbt_train_pred = gbt_model.transform(train)\n",
    "gbt_test_pred = gbt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction   0.0  1.0\n",
       "0                1     7  135\n",
       "1                0  1441    0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "gbt_train_confuse = gbt_train_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "gbt_train_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction  0.0  1.0\n",
       "0                1   50   14\n",
       "1                0  632   17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for test data\n",
    "gbt_test_confuse = gbt_test_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "gbt_test_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set:  0.9747292418772564\n",
      "F1 score for test set:  0.29473684210526313\n"
     ]
    }
   ],
   "source": [
    "# output the f1 score\n",
    "print('F1 score for training set: ',f1_score.evaluate(gbt_train_pred))\n",
    "print('F1 score for test set: ',f1_score.evaluate(gbt_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set:  0.9955780164245104\n",
      "Accuracy for test set:  0.906030855539972\n"
     ]
    }
   ],
   "source": [
    "# output the accuracy\n",
    "print('Accuracy for training set: ',accuracy.evaluate(gbt_train_pred))\n",
    "print('Accuracy for test set: ',accuracy.evaluate(gbt_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation***\n",
    "\n",
    "Tune `smoothing` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create naive bayes model\n",
    "nb_cv = NaiveBayes(featuresCol='count_vec',labelCol='label',weightCol='weights')\n",
    "# parameter grid\n",
    "nb_pars = ParamGridBuilder().addGrid(nb_cv.smoothing,[0.5,1,2,5]).build()\n",
    "# create cross validator\n",
    "cv_nb = stratifiedCV().setEstimator(nb_cv)\\\n",
    "                      .setEvaluator(f1_score)\\\n",
    "                      .setEstimatorParamMaps(nb_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best smoothing value:  1.0\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_nb_model = cv_nb.fit(train)\n",
    "# get best model\n",
    "best_nb = cv_nb_model.bestModel\n",
    "# output best parameter\n",
    "print('Best smoothing value: ',best_nb._java_obj.getSmoothing())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create naive bayes model\n",
    "nb_cv = NaiveBayes(featuresCol='count_vec',labelCol='label',weightCol='weights')\n",
    "# parameter grid\n",
    "nb_pars = ParamGridBuilder().addGrid(nb_cv.smoothing,[0.6,0.8,1,1.5]).build()\n",
    "# create cross validator\n",
    "cv_nb = stratifiedCV().setEstimator(nb_cv)\\\n",
    "                      .setEvaluator(f1_score)\\\n",
    "                      .setEstimatorParamMaps(nb_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best smoothing value:  0.6\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_nb_model = cv_nb.fit(train)\n",
    "# get best model\n",
    "best_nb = cv_nb_model.bestModel\n",
    "# output best parameter\n",
    "print('Best smoothing value: ',best_nb._java_obj.getSmoothing())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Final Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "nb = NaiveBayes(featuresCol='count_vec',labelCol='label',weightCol='weights',smoothing=0.6)\n",
    "# train the model\n",
    "nb_model = nb.fit(train)\n",
    "# obtain predictions\n",
    "nb_train_pred = nb_model.transform(train)\n",
    "nb_test_pred = nb_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1272</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction   0.0  1.0\n",
       "0                1    25  117\n",
       "1                0  1272  169"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "nb_train_confuse = nb_train_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "nb_train_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction  0.0  1.0\n",
       "0                1   17   47\n",
       "1                0  579   70"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "nb_test_confuse = nb_test_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "nb_test_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set:  0.5467289719626168\n",
      "F1 score for test set:  0.5193370165745856\n"
     ]
    }
   ],
   "source": [
    "# output the f1 score\n",
    "print('F1 score for training set: ',f1_score.evaluate(nb_train_pred))\n",
    "print('F1 score for test set: ',f1_score.evaluate(nb_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set:  0.8774478837650032\n",
      "Accuracy for test set:  0.8779803646563815\n"
     ]
    }
   ],
   "source": [
    "# output the accuracy\n",
    "print('Accuracy for training set: ',accuracy.evaluate(nb_train_pred))\n",
    "print('Accuracy for test set: ',accuracy.evaluate(nb_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Final Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "ols = LogisticRegression(featuresCol='count_vec',labelCol='label',\n",
    "                         weightCol='weights',elasticNetParam=0,regParam=0)\n",
    "# train the model\n",
    "ols_model = ols.fit(train)\n",
    "# obtain predictions\n",
    "ols_train_pred = ols_model.transform(train)\n",
    "ols_test_pred = ols_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1420</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction   0.0  1.0\n",
       "0                1     0  142\n",
       "1                0  1420   21"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "ols_train_confuse = ols_train_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "ols_train_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction  0.0  1.0\n",
       "0                1   33   31\n",
       "1                0  582   67"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for test data\n",
    "ols_test_confuse = ols_test_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "ols_test_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set:  0.9311475409836066\n",
      "F1 score for test set:  0.3827160493827161\n"
     ]
    }
   ],
   "source": [
    "# output the f1 score\n",
    "print('F1 score for training set: ',f1_score.evaluate(ols_train_pred))\n",
    "print('F1 score for test set: ',f1_score.evaluate(ols_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set:  0.9867340492735313\n",
      "Accuracy for test set:  0.8597475455820477\n"
     ]
    }
   ],
   "source": [
    "# output the accuracy\n",
    "print('Accuracy for training set: ',accuracy.evaluate(ols_train_pred))\n",
    "print('Accuracy for test set: ',accuracy.evaluate(ols_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation***\n",
    "\n",
    "Tune `regParam` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lasso model\n",
    "lasso_cv = LogisticRegression(featuresCol='count_vec',labelCol='label',\n",
    "                              weightCol='weights',elasticNetParam=1)\n",
    "# parameter grid\n",
    "lasso_pars = ParamGridBuilder().addGrid(lasso_cv.regParam,[0.01,0.1,1,10]).build()\n",
    "# create cross validator\n",
    "cv_lasso = stratifiedCV().setEstimator(lasso_cv)\\\n",
    "                         .setEvaluator(f1_score)\\\n",
    "                         .setEstimatorParamMaps(lasso_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda:  0.01\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_lasso_model = cv_lasso.fit(train)\n",
    "# get best model\n",
    "best_lasso = cv_lasso_model.bestModel\n",
    "# output best parameter\n",
    "print('Best lambda: ',best_lasso._java_obj.getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lasso model\n",
    "lasso_cv = LogisticRegression(featuresCol='count_vec',labelCol='label',\n",
    "                              weightCol='weights',elasticNetParam=1)\n",
    "# parameter grid\n",
    "lasso_pars = ParamGridBuilder().addGrid(lasso_cv.regParam,[0.001,0.005,0.01,0.05]).build()\n",
    "# create cross validator\n",
    "cv_lasso = stratifiedCV().setEstimator(lasso_cv)\\\n",
    "                         .setEvaluator(f1_score)\\\n",
    "                         .setEstimatorParamMaps(lasso_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda:  0.01\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_lasso_model = cv_lasso.fit(train)\n",
    "# get best model\n",
    "best_lasso = cv_lasso_model.bestModel\n",
    "# output best parameter\n",
    "print('Best lambda: ',best_lasso._java_obj.getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Final Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "lasso = LogisticRegression(featuresCol='count_vec',labelCol='label',\n",
    "                         weightCol='weights',elasticNetParam=1,regParam=0.01)\n",
    "# train the model\n",
    "lasso_model = lasso.fit(train)\n",
    "# obtain predictions\n",
    "lasso_train_pred = lasso_model.transform(train)\n",
    "lasso_test_pred = lasso_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1201</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction   0.0  1.0\n",
       "0                1     2  140\n",
       "1                0  1201  240"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "lasso_train_confuse = lasso_train_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "lasso_train_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction  0.0  1.0\n",
       "0                1   17   47\n",
       "1                0  516  133"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for test data\n",
    "lasso_test_confuse = lasso_test_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "lasso_test_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set:  0.5363984674329502\n",
      "F1 score for test set:  0.3852459016393443\n"
     ]
    }
   ],
   "source": [
    "# output the f1 score\n",
    "print('F1 score for training set: ',f1_score.evaluate(lasso_train_pred))\n",
    "print('F1 score for test set: ',f1_score.evaluate(lasso_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set:  0.8471257106759318\n",
      "Accuracy for test set:  0.7896213183730715\n"
     ]
    }
   ],
   "source": [
    "# output the accuracy\n",
    "print('Accuracy for training set: ',accuracy.evaluate(lasso_train_pred))\n",
    "print('Accuracy for test set: ',accuracy.evaluate(lasso_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation***\n",
    "\n",
    "Tune `regParam` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ridge model\n",
    "ridge_cv = LogisticRegression(featuresCol='count_vec',labelCol='label',\n",
    "                              weightCol='weights',elasticNetParam=0)\n",
    "# parameter grid\n",
    "ridge_pars = ParamGridBuilder().addGrid(ridge_cv.regParam,[0.01,0.1,1,10]).build()\n",
    "# create cross validator\n",
    "cv_ridge = stratifiedCV().setEstimator(ridge_cv)\\\n",
    "                         .setEvaluator(f1_score)\\\n",
    "                         .setEstimatorParamMaps(ridge_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda:  1.0\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_ridge_model = cv_ridge.fit(train)\n",
    "# get best model\n",
    "best_ridge = cv_ridge_model.bestModel\n",
    "# output best parameter\n",
    "print('Best lambda: ',best_ridge._java_obj.getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ridge model\n",
    "ridge_cv = LogisticRegression(featuresCol='count_vec',labelCol='label',\n",
    "                              weightCol='weights',elasticNetParam=0)\n",
    "# parameter grid\n",
    "ridge_pars = ParamGridBuilder().addGrid(ridge_cv.regParam,[0.5,1,3,5,7,9]).build()\n",
    "# create cross validator\n",
    "cv_ridge = stratifiedCV().setEstimator(ridge_cv)\\\n",
    "                         .setEvaluator(f1_score)\\\n",
    "                         .setEstimatorParamMaps(ridge_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda:  1.0\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_ridge_model = cv_ridge.fit(train)\n",
    "# get best model\n",
    "best_ridge = cv_ridge_model.bestModel\n",
    "# output best parameter\n",
    "print('Best lambda: ',best_ridge._java_obj.getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Final Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "ridge = LogisticRegression(featuresCol='count_vec',labelCol='label',\n",
    "                         weightCol='weights',elasticNetParam=0,regParam=1)\n",
    "# train the model\n",
    "ridge_model = ridge.fit(train)\n",
    "# obtain predictions\n",
    "ridge_train_pred = ridge_model.transform(train)\n",
    "ridge_test_pred = ridge_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1351</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction   0.0  1.0\n",
       "0                1    28  114\n",
       "1                0  1351   90"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "ridge_train_confuse = ridge_train_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "ridge_train_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>617</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction  0.0  1.0\n",
       "0                1   27   37\n",
       "1                0  617   32"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for test data\n",
    "ridge_test_confuse = ridge_test_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "ridge_test_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set:  0.6589595375722543\n",
      "F1 score for test set:  0.556390977443609\n"
     ]
    }
   ],
   "source": [
    "# output the f1 score\n",
    "print('F1 score for training set: ',f1_score.evaluate(ridge_train_pred))\n",
    "print('F1 score for test set: ',f1_score.evaluate(ridge_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set:  0.9254579911560329\n",
      "Accuracy for test set:  0.9172510518934082\n"
     ]
    }
   ],
   "source": [
    "# output the accuracy\n",
    "print('Accuracy for training set: ',accuracy.evaluate(ridge_train_pred))\n",
    "print('Accuracy for test set: ',accuracy.evaluate(ridge_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation***\n",
    "\n",
    "Tune `regParam` and `elasticNetParam` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create elastic net model\n",
    "en_cv = LogisticRegression(featuresCol='count_vec',labelCol='label',weightCol='weights')\n",
    "# parameter grid\n",
    "en_pars = ParamGridBuilder().addGrid(en_cv.regParam,[0.01,0.1,1,10])\\\n",
    "                            .addGrid(en_cv.elasticNetParam,[0.1,0.3,0.5,0.7,0.9]).build()\n",
    "# create cross validator\n",
    "cv_en = stratifiedCV().setEstimator(en_cv)\\\n",
    "                      .setEvaluator(f1_score)\\\n",
    "                      .setEstimatorParamMaps(en_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda:  0.1\n",
      "Best elastic net parameter:  0.1\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_en_model = cv_en.fit(train)\n",
    "# get best model\n",
    "best_en = cv_en_model.bestModel\n",
    "# output best parameter\n",
    "print('Best lambda: ',best_en._java_obj.getRegParam())\n",
    "print('Best elastic net parameter: ',best_en._java_obj.getElasticNetParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Final Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "en = LogisticRegression(featuresCol='count_vec',labelCol='label',\n",
    "                        weightCol='weights',elasticNetParam=0.1,regParam=0.1)\n",
    "# train the model\n",
    "en_model = en.fit(train)\n",
    "# obtain predictions\n",
    "en_train_pred = en_model.transform(train)\n",
    "en_test_pred = en_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1309</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction   0.0  1.0\n",
       "0                1    14  128\n",
       "1                0  1309  132"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "en_train_confuse = en_train_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "en_train_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>588</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction  0.0  1.0\n",
       "0                1   26   38\n",
       "1                0  588   61"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for test data\n",
    "en_test_confuse = en_test_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "en_test_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set:  0.6368159203980099\n",
      "F1 score for test set:  0.4662576687116564\n"
     ]
    }
   ],
   "source": [
    "# output the f1 score\n",
    "print('F1 score for training set: ',f1_score.evaluate(en_train_pred))\n",
    "print('F1 score for test set: ',f1_score.evaluate(en_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set:  0.9077700568540745\n",
      "Accuracy for test set:  0.8779803646563815\n"
     ]
    }
   ],
   "source": [
    "# output the accuracy\n",
    "print('Accuracy for training set: ',accuracy.evaluate(en_train_pred))\n",
    "print('Accuracy for test set: ',accuracy.evaluate(en_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Validation***\n",
    "\n",
    "Tune `regParam` and `maxIter` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear support vector machine model\n",
    "lsv_cv = LinearSVC(featuresCol='count_vec',labelCol='label',weightCol='weights')\n",
    "# parameter grid\n",
    "lsv_pars = ParamGridBuilder().addGrid(lsv_cv.regParam,[0,0.01,0.1,1,10])\\\n",
    "                             .addGrid(lsv_cv.maxIter,[50,100,200,300]).build()\n",
    "# create cross validator\n",
    "cv_lsv = stratifiedCV().setEstimator(lsv_cv)\\\n",
    "                       .setEvaluator(f1_score)\\\n",
    "                       .setEstimatorParamMaps(lsv_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best reg parameter:  0.01\n",
      "Best : max iterations 200\n"
     ]
    }
   ],
   "source": [
    "# run cross validation\n",
    "cv_lsv_model = cv_lsv.fit(train)\n",
    "# get best model\n",
    "best_lsv = cv_lsv_model.bestModel\n",
    "# output best parameter\n",
    "print('Best reg parameter: ',best_lsv._java_obj.getRegParam())\n",
    "print('Best : max iterations',best_lsv._java_obj.getMaxIter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Final Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "lsv = LinearSVC(featuresCol='count_vec',labelCol='label',\n",
    "                weightCol='weights',regParam=0.01,maxIter=200)\n",
    "# train the model\n",
    "lsv_model = lsv.fit(train)\n",
    "# obtain predictions\n",
    "lsv_train_pred = lsv_model.transform(train)\n",
    "lsv_test_pred = lsv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1374</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction   0.0  1.0\n",
       "0                1     6  136\n",
       "1                0  1374   67"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for training data\n",
    "lsv_train_confuse = lsv_train_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "lsv_train_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>607</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_prediction  0.0  1.0\n",
       "0                1   34   30\n",
       "1                0  607   42"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for test data\n",
    "lsv_test_confuse = lsv_test_pred.select('label','prediction')\n",
    "# 'label' is row and 'prediction' is column\n",
    "lsv_test_confuse.stat.crosstab('label','prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set:  0.7884057971014492\n",
      "F1 score for test set:  0.4411764705882353\n"
     ]
    }
   ],
   "source": [
    "# output the f1 score\n",
    "print('F1 score for training set: ',f1_score.evaluate(lsv_train_pred))\n",
    "print('F1 score for test set: ',f1_score.evaluate(lsv_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set:  0.9538850284270373\n",
      "Accuracy for test set:  0.8934081346423562\n"
     ]
    }
   ],
   "source": [
    "# output the accuracy\n",
    "print('Accuracy for training set: ',accuracy.evaluate(lsv_train_pred))\n",
    "print('Accuracy for test set: ',accuracy.evaluate(lsv_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Best Model\n",
    "\n",
    "The best model was ridge regression because it had the largest f1 score on the test set. I will use this model as my final model for predicting sentiment of Amazon Alexa reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ml_results' (list)\n"
     ]
    }
   ],
   "source": [
    "# save data frames\n",
    "ml_results = [ridge_test_pred.toPandas(),ridge_model.summary.pr.toPandas(),ridge_model.coefficients.toArray()]\n",
    "%store ml_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
