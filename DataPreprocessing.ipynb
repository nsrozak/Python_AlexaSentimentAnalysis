{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Link to dataset: https://www.kaggle.com/sid321axn/amazon-alexa-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global imports\n",
    "# pyspark\n",
    "import pyspark\n",
    "from pyspark.sql.session import SparkSession\n",
    "import pyspark.sql.functions as W\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "# time\n",
    "from pyspark.sql.functions import unix_timestamp, from_unixtime\n",
    "from pyspark.sql.types import TimestampType\n",
    "# text transformations\n",
    "import contractions\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------------+----------------+--------+\n",
      "|rating|     date|       variation|verified_reviews|feedback|\n",
      "+------+---------+----------------+----------------+--------+\n",
      "|     5|31-Jul-18|Charcoal Fabric |   Love my Echo!|       1|\n",
      "|     5|31-Jul-18|Charcoal Fabric |       Loved it!|       1|\n",
      "+------+---------+----------------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "df = spark.read.option('delimiter','\\t').csv('amazon_alexa.tsv',header=True,inferSchema=True)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  3150\n",
      "Number of columns:  5\n"
     ]
    }
   ],
   "source": [
    "# output dimensions of the dataset\n",
    "print(\"Number of rows: \",df.count())\n",
    "print(\"Number of columns: \",len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rating', 'int'),\n",
       " ('date', 'string'),\n",
       " ('variation', 'string'),\n",
       " ('verified_reviews', 'string'),\n",
       " ('feedback', 'int')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output data types of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|rating|\n",
      "+------+\n",
      "|     1|\n",
      "|     2|\n",
      "+------+\n",
      "\n",
      "+------+\n",
      "|rating|\n",
      "+------+\n",
      "|     3|\n",
      "|     5|\n",
      "|     4|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine what the variable 'feedback' means\n",
    "df.where(W.col('feedback') == 0).select('rating').distinct().show()\n",
    "df.where(W.col('feedback') == 1).select('rating').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Columns\n",
    "\n",
    "`feedback` is used instead of `rating` to create a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+----------------+--------+\n",
      "|     date|       variation|verified_reviews|feedback|\n",
      "+---------+----------------+----------------+--------+\n",
      "|31-Jul-18|Charcoal Fabric |   Love my Echo!|       1|\n",
      "|31-Jul-18|Charcoal Fabric |       Loved it!|       1|\n",
      "+---------+----------------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select columns for further study\n",
    "df = df.drop('rating')\n",
    "# confirm it worked\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "The dataset did not have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----------------+--------+\n",
      "|date|variation|verified_reviews|feedback|\n",
      "+----+---------+----------------+--------+\n",
      "|   0|        0|               0|       0|\n",
      "+----+---------+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of missing values in each column\n",
    "df.select(*(W.sum(W.col(c).isNull().cast('int')).alias(c) for c in df.columns)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates\n",
    "\n",
    "I chose to handle duplicates at a later stage, after I apply transformations to the dataset to extract more informtion from the `verified_reviews` column. Short reviews, like \"Love it,\" are probably unique values. However, longer reviews, like \"very handy in the kitchen, sets timer and gives me extra help on setting oven temps,\" were probably mistakenly entered twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2427"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of distinct observations\n",
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------+-----+\n",
      "|     date|           variation|    verified_reviews|feedback|count|\n",
      "+---------+--------------------+--------------------+--------+-----+\n",
      "|30-Jul-18|   Sandstone Fabric |Love my Echo. Sti...|       1|    2|\n",
      "|30-Jul-18|Heather Gray Fabric |so far love it wo...|       1|    2|\n",
      "|29-Jul-18|    Charcoal Fabric |Got a good deal a...|       1|    2|\n",
      "|30-Jul-18|          Black  Dot|Love it!! Donâ€™t k...|       1|    2|\n",
      "|28-Jul-18|    Charcoal Fabric |      Works awesome!|       1|    2|\n",
      "|30-Jul-18|          Black  Dot|This worked well ...|       0|    2|\n",
      "|30-Jul-18|          White  Dot|Alexa seems to ge...|       1|    2|\n",
      "|30-Jul-18|          White  Dot|I was hoping the ...|       1|    2|\n",
      "|30-Jul-18|    Charcoal Fabric |I love having an ...|       1|    2|\n",
      "|29-Jul-18|    Charcoal Fabric |This was given to...|       1|    2|\n",
      "|31-Jul-18|          Black  Dot|                    |       1|    2|\n",
      "|30-Jul-18|          Black  Dot|Got this for my 2...|       1|    2|\n",
      "|29-Jul-18|   Sandstone Fabric |          I love it!|       1|    2|\n",
      "|30-Jul-18|          White  Dot|HANDY AS HELL 10/...|       1|    2|\n",
      "|30-Jul-18|          White  Dot|Great. Definitely...|       1|    2|\n",
      "|30-Jul-18|          Black  Dot|I do love these t...|       1|    2|\n",
      "|30-Jul-18|   Sandstone Fabric |awesome.understan...|       1|    2|\n",
      "|29-Jul-18|Heather Gray Fabric |Bought this for m...|       1|    2|\n",
      "|30-Jul-18|Heather Gray Fabric |I love it, wife h...|       1|    2|\n",
      "|30-Jul-18|    Charcoal Fabric |Excelente, lo uni...|       1|    2|\n",
      "+---------+--------------------+--------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output rows that are duplicates\n",
    "df.groupBy('date','variation','verified_reviews','feedback')\\\n",
    "  .count()\\\n",
    "  .where(W.col('count')>1)\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `variation` Variable\n",
    "\n",
    "All levels in `variation` were properly entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|variation                   |\n",
      "+----------------------------+\n",
      "|Heather Gray Fabric         |\n",
      "|Black  Dot                  |\n",
      "|Oak Finish                  |\n",
      "|Configuration: Fire TV Stick|\n",
      "|Sandstone Fabric            |\n",
      "|White  Show                 |\n",
      "|White  Plus                 |\n",
      "|White  Spot                 |\n",
      "|Black  Spot                 |\n",
      "|Black  Show                 |\n",
      "|Walnut Finish               |\n",
      "|White                       |\n",
      "|Charcoal Fabric             |\n",
      "|White  Dot                  |\n",
      "|Black  Plus                 |\n",
      "|Black                       |\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confirm all observations were \n",
    "df.select('variation').distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `date` Variable\n",
    "\n",
    "Convert `date` from `StringType` to `DateType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------+-------------------+\n",
      "|       variation|verified_reviews|feedback|               date|\n",
      "+----------------+----------------+--------+-------------------+\n",
      "|Charcoal Fabric |   Love my Echo!|       1|2018-07-31 00:00:00|\n",
      "|Charcoal Fabric |       Loved it!|       1|2018-07-31 00:00:00|\n",
      "+----------------+----------------+--------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert date variable from string to date type\n",
    "df = df.withColumnRenamed('date','date2')\n",
    "# convert to timestamp type\n",
    "df = df.withColumn('date',from_unixtime(unix_timestamp('date2','dd-MMM-yy')))\n",
    "df = df.withColumn('date',df['date'].cast(TimestampType()))\n",
    "# remove the old date column\n",
    "df = df.drop('date2')\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `feedback` Variable\n",
    "\n",
    "Since this is an imbalanced classification problem, change feedback variable values so the majority class is class `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|feedback|count|\n",
      "+--------+-----+\n",
      "|       1| 2893|\n",
      "|       0|  257|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show that it is an imbalanced classification problem\n",
    "df.groupby('feedback').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|feedback|label|\n",
      "+--------+-----+\n",
      "|       1|    0|\n",
      "|       1|    0|\n",
      "+--------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dictionary\n",
    "feedback_dict = {0:1,1:0}\n",
    "# create a mapping function\n",
    "map_func = W.udf(lambda x: feedback_dict[x])\n",
    "# convert values\n",
    "df = df.withColumn('label',map_func('feedback').cast(IntegerType()))\n",
    "# output data frame\n",
    "df.select('feedback','label').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  257|\n",
      "|    0| 2893|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confirm label worked correctly\n",
    "df.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Create `length` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------+-------------------+-----+-------------+\n",
      "|       variation|verified_reviews|feedback|               date|label|   text_clean|\n",
      "+----------------+----------------+--------+-------------------+-----+-------------+\n",
      "|Charcoal Fabric |   Love my Echo!|       1|2018-07-31 00:00:00|    0|Love my Echo!|\n",
      "|Charcoal Fabric |       Loved it!|       1|2018-07-31 00:00:00|    0|    Loved it!|\n",
      "+----------------+----------------+--------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function for expanding contractions\n",
    "def fix_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "# udf for expanding contractions\n",
    "contractions_udf = W.udf(lambda row: fix_contractions(row) , StringType())\n",
    "# add column with contractions expanded\n",
    "df = df.withColumn('text_clean', contractions_udf('verified_reviews'))\n",
    "# output data frame\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------+-------------------+-----+-------------+----------------+\n",
      "|       variation|verified_reviews|feedback|               date|label|   text_clean|        text_vec|\n",
      "+----------------+----------------+--------+-------------------+-----+-------------+----------------+\n",
      "|Charcoal Fabric |   Love my Echo!|       1|2018-07-31 00:00:00|    0|Love my Echo!|[love, my, echo]|\n",
      "|Charcoal Fabric |       Loved it!|       1|2018-07-31 00:00:00|    0|    Loved it!|     [loved, it]|\n",
      "+----------------+----------------+--------+-------------------+-----+-------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text\n",
    "rt = RegexTokenizer().setInputCol('text_clean')\\\n",
    "                     .setOutputCol('text_vec')\\\n",
    "                     .setPattern('\\s+|[\\W]')\\\n",
    "                     .setToLowercase(True)\n",
    "# transform data\n",
    "df = rt.transform(df)\n",
    "# output dataframe\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `length` Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------+-------------------+-----+-------------+----------------+------+\n",
      "|       variation|verified_reviews|feedback|               date|label|   text_clean|        text_vec|length|\n",
      "+----------------+----------------+--------+-------------------+-----+-------------+----------------+------+\n",
      "|Charcoal Fabric |   Love my Echo!|       1|2018-07-31 00:00:00|    0|Love my Echo!|[love, my, echo]|     3|\n",
      "|Charcoal Fabric |       Loved it!|       1|2018-07-31 00:00:00|    0|    Loved it!|     [loved, it]|     2|\n",
      "+----------------+----------------+--------+-------------------+-----+-------------+----------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function for getting the length\n",
    "def length(text):\n",
    "    return len(text)\n",
    "# udf for getting the length\n",
    "length_udf = W.udf(lambda row: length(row), IntegerType())\n",
    "# add column with length\n",
    "df = df.withColumn('length', length_udf('text_vec'))\n",
    "# output data frame\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3066"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the rows where the length is greater than 0\n",
    "df = df.where(W.col('length')>0)\n",
    "# count the number of rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frames for Exploratory Data Analysis and Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-------------------+-------------+------+-----+\n",
      "|       variation|verified_reviews|               date|   text_clean|length|label|\n",
      "+----------------+----------------+-------------------+-------------+------+-----+\n",
      "|Charcoal Fabric |   Love my Echo!|2018-07-31 00:00:00|Love my Echo!|     3|    0|\n",
      "|Charcoal Fabric |       Loved it!|2018-07-31 00:00:00|    Loved it!|     2|    0|\n",
      "+----------------+----------------+-------------------+-------------+------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create data frame for eda\n",
    "eda_df = df.select('variation','verified_reviews','date','text_clean','length','label')\n",
    "# output data frame\n",
    "eda_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----+\n",
      "|verified_reviews|        text_vec|label|\n",
      "+----------------+----------------+-----+\n",
      "|   Love my Echo!|[love, my, echo]|    0|\n",
      "|       Loved it!|     [loved, it]|    0|\n",
      "+----------------+----------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create data frame for ml\n",
    "ml_df = df.select('verified_reviews','text_vec','label')\n",
    "# output data frame\n",
    "ml_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Duplicates\n",
    "\n",
    "Duplicate rows with `length > 5` were removed in `eda_df`. Duplicate rows were removed `ml_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2380"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of distinct observations in eda_df\n",
    "eda_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------------------+--------------------+------+-----+\n",
      "|variation|    verified_reviews|               date|          text_clean|length|label|\n",
      "+---------+--------------------+-------------------+--------------------+------+-----+\n",
      "|    Black|Love my Alexa Ech...|2018-06-11 00:00:00|Love my Alexa Ech...|    66|    0|\n",
      "|    Black|Overall good devi...|2018-05-31 00:00:00|Overall good devi...|    32|    0|\n",
      "+---------+--------------------+-------------------+--------------------+------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate rows where length>5\n",
    "eda_df = eda_df.withColumn('temp_id', W.monotonically_increasing_id())\n",
    "window = Window.partitionBy([W.col('variation'),W.col('verified_reviews'),W.col('label'),W.col('date')])\\\n",
    "               .orderBy('temp_id')\n",
    "eda_df = eda_df.withColumn('id', W.dense_rank().over(window)).filter((W.col('length')<=5)|(W.col('id')==1))\n",
    "# drop extra columns\n",
    "eda_df = eda_df.drop('temp_id','id')\n",
    "# output data frame\n",
    "eda_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2554"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm duplicates were removed\n",
    "eda_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2296"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of distinct observations in ml_df\n",
    "ml_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2296"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates for ml_df\n",
    "ml_df = ml_df.dropDuplicates()\n",
    "# confirm that duplicates were dropped\n",
    "ml_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+\n",
      "|    verified_reviews|            text_vec|label|       text_vec_stop|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|Great addition to...|[great, addition,...|    0|[great, addition,...|\n",
      "|it's great for mu...|[it, is, great, f...|    0|[great, music, li...|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create english stopwords\n",
    "english = StopWordsRemover().loadDefaultStopWords('english')\n",
    "# stopwords transformer\n",
    "stops = StopWordsRemover().setStopWords(english)\\\n",
    "                          .setInputCol('text_vec')\\\n",
    "                          .setOutputCol('text_vec_stop')\n",
    "# transform dataframe\n",
    "ml_df = stops.transform(ml_df)\n",
    "# output dataframe\n",
    "ml_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematize Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|    verified_reviews|            text_vec|label|       text_vec_stop|        text_vec_lem|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|Great addition to...|[great, addition,...|    0|[great, addition,...|[great, addition,...|\n",
      "|it's great for mu...|[it, is, great, f...|    0|[great, music, li...|[great, music, li...|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create word lemmatizer object\n",
    "wnl = WordNetLemmatizer()\n",
    "# function for lemmatizing words\n",
    "def wnl_row(row):\n",
    "    return [wnl.lemmatize(x) for x in row]\n",
    "# udf for lemmatizing words\n",
    "lemmatizer_udf = W.udf(lambda row: wnl_row(row) , ArrayType(StringType()))\n",
    "# create column of lemmatized words\n",
    "ml_df = ml_df.withColumn('text_vec_lem', lemmatizer_udf('text_vec_stop'))\n",
    "# output dataframe\n",
    "ml_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Sets\n",
    "\n",
    "70% of the data was used to train the models, 30% of the data was used to test the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets\n",
    "train,test = ml_df.randomSplit([0.7,0.3],116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train set:  1583\n",
      "Number of rows in test set:  713\n"
     ]
    }
   ],
   "source": [
    "# output counts for train and test sets\n",
    "print(\"Number of rows in train set: \",train.count())\n",
    "print(\"Number of rows in test set: \",test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Words\n",
    "\n",
    "Create a vocabulary of words that appears in 1% of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|count_vec                                                                                                                                                                                                                                                                                                                         |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(495,[1,2,43,284],[1.0,1.0,1.0,1.0])                                                                                                                                                                                                                                                                                              |\n",
      "|(495,[0,2,7,8,10,14,17,18,21,24,30,32,38,40,47,52,63,71,74,100,107,108,113,120,121,130,131,145,153,187,191,206,228,231,256,258,288,329,342,349,473,487],[3.0,1.0,2.0,2.0,1.0,1.0,1.0,2.0,1.0,1.0,2.0,2.0,1.0,1.0,1.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create transformer\n",
    "cv = CountVectorizer().setInputCol('text_vec_lem')\\\n",
    "                      .setOutputCol('count_vec')\\\n",
    "                      .setMinDF(train.count()*0.005)\n",
    "# fit the transformer\n",
    "model_cv = cv.fit(train)\n",
    "# transform the data\n",
    "train = model_cv.transform(train)\n",
    "# output the vectorized column\n",
    "train.select('count_vec').show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|count_vec                                                                                            |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(495,[],[])                                                                                          |\n",
      "|(495,[1,5,6,7,10,11,45,72,123,143,198,266,418],[2.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the vocabulary on the test data\n",
    "test = model_cv.transform(test)\n",
    "# output the vectorized column\n",
    "test.select('count_vec').show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary\n",
    "vocab = model_cv.vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `weights` Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-------------------+\n",
      "|    verified_reviews|            text_vec|label|       text_vec_stop|        text_vec_lem|           count_vec|            weights|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-------------------+\n",
      "|Great addition to...|[great, addition,...|    0|[great, addition,...|[great, addition,...|(495,[1,2,43,284]...|0.08970309538850285|\n",
      "|I love this littl...|[i, love, this, l...|    0|[love, little, sp...|[love, little, sp...|(495,[0,2,7,8,10,...|0.08970309538850285|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# obtain balancing ratio\n",
    "num_0 = train.select('label').where(W.col('label')==0).count()\n",
    "total = train.count()\n",
    "ratio = num_0/total\n",
    "# create weights column\n",
    "train = train.withColumn('weights', W.when(train.label==1,ratio).otherwise(1-ratio))\n",
    "train.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge `eda_df` and `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------------+--------------------+------+--------------------+-----+--------------------+--------------------+--------------------+-------------------+\n",
      "|    verified_reviews|  variation|               date|          text_clean|length|            text_vec|label|       text_vec_stop|        text_vec_lem|           count_vec|            weights|\n",
      "+--------------------+-----------+-------------------+--------------------+------+--------------------+-----+--------------------+--------------------+--------------------+-------------------+\n",
      "|Love my Alexa Ech...|      Black|2018-06-11 00:00:00|Love my Alexa Ech...|    66|[love, my, alexa,...|    0|[love, alexa, ech...|[love, alexa, ech...|(495,[0,1,2,3,4,7...|0.08970309538850285|\n",
      "|Not that much dif...|Black  Plus|2018-07-30 00:00:00|Not that much dif...|    58|[not, that, much,...|    0|[much, different,...|[much, different,...|(495,[3,8,15,26,2...|0.08970309538850285|\n",
      "+--------------------+-----------+-------------------+--------------------+------+--------------------+-----+--------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create `eda_df_train` and drop 'label' since it exists in `train`\n",
    "eda_df_train = eda_df.drop('label')\n",
    "# join the data frames\n",
    "eda_df_train = eda_df_train.join(train,on=['verified_reviews'],how='inner')\n",
    "# output the data frame\n",
    "eda_df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1771"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the number of rows\n",
    "eda_df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------------------+--------------------+------+\n",
      "|  variation|label|               date|          text_clean|length|\n",
      "+-----------+-----+-------------------+--------------------+------+\n",
      "|      Black|    0|2018-06-11 00:00:00|Love my Alexa Ech...|    66|\n",
      "|Black  Plus|    0|2018-07-30 00:00:00|Not that much dif...|    58|\n",
      "+-----------+-----+-------------------+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select columns\n",
    "eda_df_train = eda_df_train.select('variation','label','date','text_clean','length')\n",
    "# output data frame\n",
    "eda_df_train.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|           count_vec|label|            weights|\n",
      "+--------------------+-----+-------------------+\n",
      "|(495,[1,2,43,284]...|    0|0.08970309538850285|\n",
      "|(495,[0,2,7,8,10,...|    0|0.08970309538850285|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select columns for train\n",
    "train = train.select('count_vec','label','weights')\n",
    "# confirm it worked\n",
    "train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           count_vec|label|\n",
      "+--------------------+-----+\n",
      "|         (495,[],[])|    0|\n",
      "|(495,[1,5,6,7,10,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select columns for train\n",
    "test = test.select('count_vec','label')\n",
    "# confirm it worked\n",
    "test.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'dfs' (list)\n"
     ]
    }
   ],
   "source": [
    "# store dataframes for additional programs\n",
    "dfs = [train.toPandas(),test.toPandas(),eda_df_train.toPandas(),vocab]\n",
    "%store dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
